{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 文字列として表現されているデータのタイプ\n",
    "\n",
    "文字列データの種類：\n",
    "1. カテゴリデータ\n",
    "2. カテゴリデータを表す自由に書かれた文字列：　\n",
    "3. 構造化された文字列\n",
    "4. テキストデータ\n",
    "\n",
    "カテゴリデータ：　\n",
    "- カテゴリを表す文字列。ドロップダウンメニューの[red, blue, green]など。固定リストからのデータ。\n",
    "\n",
    "カテゴリデータを表す自由に書かれた文字列：　\n",
    "- 人に色の名前を自由に記入してもらったアンケート結果など\n",
    " - the xkcd Color Survey（https://blog.xkcd.com/2010/05/03/color-survey-results/ ）\n",
    "- カテゴリ変数にエンコード必要（どれにも割り当てられないものは新カテゴリを作成したり、otherカテゴリにまとめるなど）\n",
    "- 手作業必要（自動化困難）\n",
    "- 可能なら自由記入形式ではなく選択式を強く推奨\n",
    "\n",
    "構造化された文字列：\n",
    "- 固定カテゴリに対応せず、ある構造を持った文字列（住所、郵便番号、人名、日付、電話番号、識別番号など）\n",
    "\n",
    "テキストデータ：\n",
    "- ツイート、チャットログ、レビュー、小説、Wikipediaの記事、電子書籍など\n",
    "\n",
    "テキスト解析：\n",
    "- コーパス：　データセット。文書の集合。\n",
    "- 文書：　1つのテキストとして表現される個々のデータポイント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 例題アプリケーション：映画レビューのセンチメント分析\n",
    "\n",
    "データセット：\n",
    "- 映画レビューのテキスト。内容が肯定的(pos)か否定的(neg)かで2クラス分類。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インポート集\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "27449\n",
      "b'i was disappointed. the film was a bit predictable and did not live up to the hype plastered all over the box. Having said that, the characters were well developed, the windego myth was used in a unique premise and the house was pretty spooky but it just missed for me. I kept waiting for that big AHHHHH or BOO! But it never came.<br /><br />Furthermore the movie was plagued with poor filming of poor special effects. Thus showing to much of a bad thing and not using atmosphere and viewer imagination to create the horror and suspense. Try movies like Session 9 or the Cube if your looking for a low-budget but well conceived horror movie.'\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 映画レビューのセンチメント分析\n",
    "# データロード（http://ai.stanford.edu/~amaas/data/sentiment/）からダウンロ―ドして格納しておく）\n",
    "from sklearn.datasets import load_files\n",
    "ra = load_files(\"data/aclImdb/train/\")\n",
    "# 訓練テキスト、訓練ラベル作成\n",
    "ta, ya = ra.data, ra.target\n",
    "print(type(ta))\n",
    "print(len(ta))\n",
    "print(ta[1])\n",
    "print(ya[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> レビュー数：27449件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改行をなくす（空白に置換）\n",
    "ta = [doc.replace(b\"<br />\", b\" \") for doc in ta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500,  2449], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "[12500 12500]\n"
     ]
    }
   ],
   "source": [
    "# テストデータも同様に処理\n",
    "# データロード\n",
    "re = load_files(\"data/aclImdb/test/\")\n",
    "# テストテキスト、テストラベル作成\n",
    "te, ye = re.data, re.target\n",
    "print(len(te))\n",
    "print(np.bincount(ye))\n",
    "# 改行をなくす（空白に置換）\n",
    "te = [doc.replace(b\"<br />\", b\" \") for doc in te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機械学習で扱えるように文字列を数字に変換する必要あり"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3　Bag of Wordsによるテキスト表現\n",
    "\n",
    "Bag of Words（BoW)：\n",
    "- 言葉の袋。構文無視して単語の出現数だけ数える（コーパスの単語がテキストに出現する数をカウント）\n",
    "- 計算手順：\n",
    " 1. トークン分割：　個々の文書を単語（＝トークン）に分割。ホワイトスペース（スペース、改行、タブ)や句読点で句切る。\n",
    " 2. ボキャブラリ構築：　全ての文書に現れる全ての単語をボキャブラリとして集め、番号を付ける（アルファベット順など）\n",
    " 3. エンコード：　個々の文書に対してボキャブラリの単語が現れる回数を数える。\n",
    "\n",
    "- 出力：　\n",
    " - 1文書1ベクトル。(1単語1特徴量(0/1)を割り当てた数値表現）\n",
    " - SciPyの疎行列。非ゼロ要素のみ格納（殆どの文書にはボキャブラリ中の単語のごく一部しか使われないため。省メモリ。）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The fool doth think he is wise,',\n",
       " 'but the wise man knows himself to be a fool']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# トイデータセット x BoW\n",
    "# データ作成（2つの文書（データ点））\n",
    "w = [\"The fool doth think he is wise,\",\n",
    "     \"but the wise man knows himself to be a fool\"]\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer使用\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer()\n",
    "# 適合（訓練データのトークン分割＋ボキャブラリ構築）\n",
    "v.fit(w)\n",
    "# ボキャブラリ\n",
    "print(v.vocabulary_)\n",
    "# ボキャブラリサイズ\n",
    "print(len(v.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<2x13 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>\n",
      "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# BoW作成\n",
    "bow = v.transform(w)\n",
    "# bowの解説\n",
    "print(repr(bow))\n",
    "# bowの内容（SciPy疎行列をnumpy（蜜）行列に変換（実際には多すぎてメモリエラーの危険）。numpyは0もメモリに格納する）\n",
    "print(bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> 2x13：　文書数2、ボキャブラリ13（全文書の重複なし単語数）を表す。SciPy疎行列。\n",
    "#    2つのデータ点にそれぞれ行が割り当てられ、ボキャブラリ中の単語に各特徴量が割り当てられている。\n",
    "#    bowの内容：　各単語の出現回数。今回の2文書では、同じ単語が最大1度しか使われていないため0か1のみ。\n",
    "# 　　　　　　　　ボキャブラリの最初から、単語be：0回、but：0回、doth：1回の出現を表す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<27449x77975 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3762717 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# 映画レビューのBoW\n",
    "v = CountVectorizer().fit(ta)\n",
    "xa = v.transform(ta)\n",
    "print(repr(xa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> 文書数27449、ボキャブラリ77975。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77975\n",
      "['00', '000', '0000000000001', '000000003', '00001', '00015', '000s', '001', '003830', '006', '007', '0079', '0080', '0083', '0093638', '00am', '00pm', '00s', '01', '01pm']\n",
      "['dithers', 'dithyrambical', 'ditka', 'ditsy', 'ditties', 'ditto', 'dittrich', 'ditty', 'ditz', 'ditzy', 'diurnal', 'diva', 'divagations', 'divali', 'divas', 'dive', 'dived', 'diver', 'diverge', 'diverged']\n",
      "['00', 'adulterously', 'apostrophe', 'balooned', 'blanketed', 'bulked', 'chamberlin', 'coloured', 'crapper', 'dekho', 'disturbs', 'eighth', 'exhooker', 'flavorings', 'gaspingly', 'groove', 'heroic', 'ilses', 'irritated', 'khoobsurat', 'lengths', 'magnesium', 'meneses', 'mousse', 'nosher', 'pack', 'pierce', 'proclivity', 'reaccounting', 'richandson', 'satyr', 'sherri', 'soderberghian', 'stoppers', 'taiwan', 'tolkiens', 'unbuckles', 'verbosity', 'wicked']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "n = v.get_feature_names()\n",
    "print(len(n))\n",
    "print(n[:20])\n",
    "print(n[20010:20030])\n",
    "print(n[::2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# →　特徴量数：77975\n",
    "# 　　特徴量の最初の20個\n",
    "# 　　特徴量の20010番から20030番まで\n",
    "# 　　特徴量を2000個おきに取り出す（アルファベット順になっている）\n",
    "\n",
    "# 意味的に非常に類似した単語や、単数形と複数形などは同じ特徴量としたい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toa\\Anaconda3\\envs\\aidemy3.6\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\toa\\Anaconda3\\envs\\aidemy3.6\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8244379336583417\n"
     ]
    }
   ],
   "source": [
    "# CVスコア（ロジスティック回帰）\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "s = cross_val_score(LogisticRegression(), xa, ya, cv=5)\n",
    "# CVスコアの平均\n",
    "print(np.mean(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> 平均CVスコア88は普通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチ\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pg = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "g = GridSearchCV(LogisticRegression(), pg, cv=5)\n",
    "g.fit(xa, ya)\n",
    "# ベストCVスコア\n",
    "print(g.best_score_)\n",
    "# ベストパラメタ\n",
    "print(g.best_params_)\n",
    "# テストスコア\n",
    "xe = v.transform(te)\n",
    "print(g.score(xe, ye))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p327"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
